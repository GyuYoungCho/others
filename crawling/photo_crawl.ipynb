{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from PIL import Image\n",
    "con = sqlite3.connect('food_image.db')\n",
    "cur = con.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x158f11a9f80>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.executescript('''\n",
    "    DROP TABLE IF EXISTS food_image;\n",
    "    CREATE TABLE food_image(\n",
    "        FOOD_NAME    TEXT,\n",
    "        FOOD_IMAGE    TEXT\n",
    "    );\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.executescript('''\n",
    "#     DROP TABLE IF EXISTS IMAGE;\n",
    "#     CREATE TABLE IMAGE(\n",
    "#         FOOD_NAME    TEXT,\n",
    "#         IMAGE    BLOB\n",
    "#     );\n",
    "# ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import request\n",
    "from requests.compat import urljoin, urlparse\n",
    "from requests.exceptions import HTTPError\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "headers = {'user-agent':\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\"}\n",
    "\n",
    "def canfetch(url, agent='*', path='/'):\n",
    "    robot = RobotFileParser(urljoin(url, '/robots.txt'))\n",
    "    robot.read()\n",
    "    return robot.can_fetch(agent, urlparse(url)[2])\n",
    "    \n",
    "def download(url, params={}, headers={}, method='GET', limit=3):\n",
    "    method = method.upper()\n",
    "    if canfetch(url) == False:\n",
    "        print('[Error] ' + url)\n",
    "    else: #bot 접근 못하게 막은데있어어 else뺌\n",
    "        try:\n",
    "            resp = requests.request(method, url,\n",
    "                   params=params if method=='GET' else {},\n",
    "                   data=params if method=='POST' else {},\n",
    "                   headers=headers)\n",
    "            resp.raise_for_status()\n",
    "        except HTTPError as e:\n",
    "            if limit > 0 and e.response.status_code >= 500:\n",
    "                print(limit)\n",
    "                time.sleep(300) # => random, 1초에 1번\n",
    "                resp = download(url, params, headers, method, limit-1)\n",
    "            else:\n",
    "                print('[{}] '.format(e.response.status_code) + url)\n",
    "                print(e.response.status_code)\n",
    "                print(e.response.reason)\n",
    "                print(e.response.headers)\n",
    "        return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = download('https://www.gettyimagesbank.com/s/?lv=&st=union&mi=2&q=%25EA%25B9%2580%25EC%25B9%2598%25EC%25B0%258C%25EA%25B0%259C&ssi=go',headers = headers, method='GET')\n",
    "dom = BeautifulSoup(resp.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = ['멍게비빔밥', '새우초밥', '연어초밥', '약초비빔밥', '해물덮밥', '월남쌈', '김치찌개', '꽁치김치찌개']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('/Users/Gyu/Desktop/mywork/KData/chromedriver')\n",
    "\n",
    "for search_list in flist:\n",
    "    driver.get('https://www.gettyimagesbank.com/s/?lv=&st=union&mi=2&q='+search_list+'&ssi=go')\n",
    "    time.sleep(3)\n",
    "    if not driver.find_elements_by_css_selector('img[class=imgThumb]'):\n",
    "        continue\n",
    "    for _ in driver.find_elements_by_css_selector('img[class=imgThumb]'):\n",
    "                cur.execute('''\n",
    "            INSERT INTO food_image(FOOD_NAME, FOOD_IMAGE)\n",
    "            VALUES(?,?)''' ,[search_list,_.get_attribute('src')]\n",
    "        )\n",
    "con.commit()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from urllib.request import urlopen\n",
    "# driver = webdriver.Chrome('/Users/Gyu/Desktop/mywork/KData/chromedriver')\n",
    "\n",
    "# for search_list in flist:\n",
    "#     driver.get('https://www.gettyimagesbank.com/s/?lv=&st=union&mi=2&q='+search_list+'&ssi=go')\n",
    "#     time.sleep(3)\n",
    "#     if not driver.find_elements_by_css_selector('img[class=imgThumb]'):\n",
    "#         continue\n",
    "#     for _ in driver.find_elements_by_css_selector('img[class=imgThumb]'):\n",
    "#         img = urlopen(_.get_attribute('src'))\n",
    "#         break\n",
    "#                 cur.execute('''\n",
    "#             INSERT INTO IMAGE(FOOD_NAME, IMAGE)\n",
    "#             VALUES(?,?)''' ,[search_list,urlopen(_.get_attribute('src'))]\n",
    "#         )\n",
    "# con.commit()\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('/Users/Gyu/Desktop/mywork/KData/chromedriver')\n",
    "driver.get('https://pixabay.com/ko/photos/search/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "flist = ['토마토','고추', '당근', '마늘', '무', '호박']\n",
    "url = 'https://pixabay.com/ko/photos/search/'\n",
    "\n",
    "\n",
    "for i in flist:\n",
    "    driver.get(url + i + '/?cat=food')\n",
    "    num_of_pagedowns = 4\n",
    "    time.sleep(3)\n",
    "    while num_of_pagedowns:\n",
    "        \n",
    "        try:\n",
    "            body = driver.find_element_by_tag_name('body')\n",
    "            body.send_keys(Keys.END)\n",
    "            time.sleep(4)\n",
    "            num_of_pagedowns -= 1\n",
    "        \n",
    "            for j,_ in enumerate(driver.find_elements_by_css_selector('img')):\n",
    "                if _.get_attribute('srcset') !='':\n",
    "                    cur.execute('''\n",
    "                        INSERT INTO food_image(FOOD_NAME, FOOD_IMAGE)\n",
    "                        VALUES(?,?)''' ,[i,_.get_attribute('srcset')]\n",
    "                     )\n",
    "            time.sleep(2)\n",
    "            driver.find_element_by_xpath('//*[@id=\"content\"]/div/a').click()\n",
    "            time.sleep(3)\n",
    "        except StaleElementReferenceException:\n",
    "            pass\n",
    "con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import urlopen\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "flist = ['토마토', '사과', '딸기']\n",
    "url = 'https://www.google.com/search?q='\n",
    "detail = '&rlz=1C1NDCM_koKR830KR830&sxsrf=ALeKk02Fz_qw4R-HKvLq2RYYTPm1AoHutA:1596589422260&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiRufaK74LrAhWDPXAKHfy-Ar8Q_AUoAXoECBoQAw&biw=1920&bih=842'\n",
    "\n",
    "\n",
    "for i in flist:\n",
    "    driver.get(url + i + detail)\n",
    "    num_of_pagedowns = 1\n",
    "    time.sleep(3)\n",
    "    while num_of_pagedowns:\n",
    "        \n",
    "        \n",
    "        body = driver.find_element_by_tag_name('body')\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(2)\n",
    "        num_of_pagedowns -= 1\n",
    "        \n",
    "        for j,_ in enumerate(driver.find_elements_by_css_selector('img[class$=Q4LuWd]')[1:21]):\n",
    "            if _.get_attribute('src') !='':\n",
    "#               print(_.get_attribute('src'))\n",
    "                try:\n",
    "                    with urlopen(_.get_attribute('src')) as f:\n",
    "                        with open('img/' + i + '_' + str(j)+'.jpg','wb') as h: \n",
    "                            img = f.read()\n",
    "                            h.write(img)\n",
    "                except:\n",
    "                    with urlopen(_.get_attribute('data-src')) as f:\n",
    "                        with open('img/' + i + '_' + str(j)+'.jpg','wb') as h: \n",
    "                            img = f.read()\n",
    "                            h.write(img)\n",
    "            time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
